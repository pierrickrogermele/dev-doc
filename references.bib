% vi: fdm=marker

% Computer science {{{1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Design patterns {{{2
@book{dp1995,
	title = "Design Patterns: Elements of Reusable Object-Oriented Softwarer",
	author = "Gamma, Erich and Helm, Richard and Johnson, Ralph and Vlissides, John",
	publisher = "Addison-Wesley",
	year = {1995},
	isbn = "978-0201633610"
}

% Algorithm Engineering {{{2
@inbook{sanders2009_algoeng,
	author="Sanders, Peter",
	editor="Albers, Susanne and Alt, Helmut and N{\"a}her, Stefan",
	title="Algorithm Engineering -- An Attempt at a Definition",
	bookTitle="Efficient Algorithms: Essays Dedicated to Kurt Mehlhorn on the Occasion of His 60th Birthday",
	year="2009",
	publisher="Springer Berlin Heidelberg",
	address="Berlin, Heidelberg",
	pages="321--340",
	abstract="This paper defines algorithm engineering as a general methodology for algorithmic research. The main process in this methodology is a cycle consisting of algorithm design, analysis, implementation and experimental evaluation that resembles Popper's scientific method. Important additional issues are realistic models, algorithm libraries, benchmarks with real-world problem instances, and a strong coupling to applications. Algorithm theory with its process of subsequent modelling, design, and analysis is not a competing approach to algorithmics but an important ingredient of algorithm engineering.",
	isbn="978-3-642-03456-5",
	doi="10.1007/978-3-642-03456-5_22",
	url="https://doi.org/10.1007/978-3-642-03456-5_22"
}

% Algorithm Engineering - sorting example {{{2
@inbook{sanders2010_algoeng,
	author = {Sanders, Peter},
	title = {Algorithm Engineering – An Attempt at a Definition Using Sorting as an Example},
	booktitle = {2010 Proceedings of the Workshop on Algorithm Engineering and Experiments (ALENEX)},
	chapter = {},
	year = {2010},
	pages = {55-61},
	doi = {10.1137/1.9781611972900.6},
	URL = {https://epubs.siam.org/doi/abs/10.1137/1.9781611972900.6},
	eprint = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611972900.6}
}

% Mathematics {{{1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% The Elements of Statistical Learning {{{2
@book{statlearn2009,
	title = "The Elements of Statistical Learning - Data Mining, Inference, and Prediction",
	author = "Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome",
	publisher = "Springer",
	year = 2009,
	edition= "Second",
	isbn = "978-0387848570"
}

% Artificial Intelligence {{{1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Taxonomies {{{2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Explainable Artificial Intelligence {{{3
% From Confiance.AI project, lecture meeting.
% TOREAD
@misc{arrieta2019_explainable,
	title={Explainable Artificial Intelligence (XAI): Concepts, Taxonomies, Opportunities and Challenges toward Responsible AI}, 
	author={Alejandro Barredo Arrieta and Natalia Díaz-Rodríguez and Javier Del Ser and Adrien Bennetot and Siham Tabik and Alberto Barbado and Salvador García and Sergio Gil-López and Daniel Molina and Richard Benjamins and Raja Chatila and Francisco Herrera},
	year={2019},
	eprint={1910.10045},
	archivePrefix={arXiv},
	primaryClass={cs.AI}
}

% Four Principles of Explainable Artificial Intelligence {{{3
% TOREAD
@misc{jonathon_phillips2020_four_principles_xai,
	author = {Jonathon Phillips, P. and Hahn, Carina A. and Fontana, Peter C. and Broniatowski, David A. and Przybocki, Mark A.},
	title = {Four Principles of Explainable Artificial 3Intelligence},
	institution = {NIST},
	year = {2020},
	month = {8},
	doi = {https://doi.org/10.6028/NIST.IR.8312-draft}
}

% Explainable AI Terminology {{{3
% TOREAD
@inproceedings{clinciu2019_xai_terminology,
	author = {Clinciu, Miruna A. and Hastie, Helen F.},
	title = {A Survey of Explainable AI Terminology},
	booktitle = {1st Workshop on Interactive Natural Language Technology for Explainable Artificial Intelligence (NL4XAI 2019)},
	year = {2019},
	url = {https://www.aclweb.org/anthology/W19-8403.pdf},
	abstract = {The field of Explainable Artificial Intelligenceattempts to solve the problem of algorithmicopacity.   Many  terms  and  notions  have  beenintroduced recently to define Explainable AI,however,  these  terms  seem  to  be  used  inter-changeably,  which is leading to confusion inthis rapidly expanding field.  As a solution toovercome this problem, we present an analysisof the existing research literature and examinehow key terms, such astransparency,intelli-gibility,interpretability, andexplainabilityarereferred  to  and  in  what  context.   This  paper,thus,  moves  towards  a  standard  terminologyfor Explainable AI.}
}

% Bioinformatics {{{1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Mass spectrometry {{{2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% msPurity {{{3
% TOREAD
@article{lawson2017_mspurity,
	author = {Lawson, Thomas N. and Weber, Ralf J. M. and Jones, Martin R. and Chetwynd, Andrew J. and Rodrı́guez-Blanco, Giovanny and Di Guida, Riccardo and Viant, Mark R. and Dunn, Warwick B.},
	title = {msPurity: Automated Evaluation of Precursor Ion Purity for Mass Spectrometry-Based Fragmentation in Metabolomics},
	journal = {Analytical Chemistry},
	volume = {89},
	number = {4},
	pages = {2432-2439},
	year = {2017},
	doi = {10.1021/acs.analchem.6b04358},
	note ={PMID: 28194963},
	url = {https://doi.org/10.1021/acs.analchem.6b04358},
	eprint = {https://doi.org/10.1021/acs.analchem.6b04358},
	abstract = { Tandem mass spectrometry (MS/MS or MS2) is a widely used approach for structural annotation and identification of metabolites in complex biological samples. The importance of assessing the contribution of the precursor ion within an isolation window for MS2 experiments has been previously detailed in proteomics, where precursor ion purity influences the quality and accuracy of matching to mass spectral libraries, but to date, there has been little attention to this data-processing technique in metabolomics. Here, we present msPurity, a vendor-independent R package for liquid chromatography (LC) and direct infusion (DI) MS2 that calculates a simple metric to describe the contribution of the selected precursor. The precursor purity metric is calculated as “intensity of a selected precursor divided by the summed intensity of the isolation window”. The metric is interpolated at the recorded point of MS2 acquisition using bordering full-scan spectra. Isotopic peaks of the selected precursor can be removed, and low abundance peaks that are believed to have limited contribution to the resulting MS2 spectra are removed. Additionally, the isolation efficiency of the mass spectrometer can be taken into account. The package was applied to Data Dependent Acquisition (DDA)-based MS2 metabolomics data sets derived from three metabolomics data repositories. For the 10 LC-MS2 DDA data sets with > ±1 Da isolation windows, the median precursor purity score ranged from 0.67 to 0.96 (scale = 0 to +1). The R package was also used to assess precursor purity of theoretical isolation windows from LC-MS data sets of differing sample types. The theoretical isolation windows being the same width used for an anticipated DDA experiment (±0.5 Da). The most complex sample had a median precursor purity score of 0.46 for the 64,498 XCMS determined features, in comparison to the less spectrally complex sample that had a purity score of 0.66 for 5071 XCMS features. It has been previously reported in proteomics that a purity score of <0.5 can produce unreliable spectra matching results. With this assumption, we show that for complex samples there will be a large number of metabolites where traditional DDA approaches will struggle to provide reliable annotations or accurate matches to mass spectral libraries. }
}

% Databases {{{2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% "Chemoinformatics-based enumeration of chemical libraries: a tutorial {{{3
% TOREAD
@article{saldivargonzalez2020,
author="Sald{\'{\i}}var-Gonz{\'a}lez, Fernanda I.
and Huerta-Garc{\'{\i}}a, C. Sebastian
and Medina-Franco, Jos{\'e} L.",
title="Chemoinformatics-based enumeration of chemical libraries: a tutorial",
journal="Journal of Cheminformatics",
year="2020",
month="Oct",
day="27",
volume="12",
number="1",
pages="64",
abstract="Virtual compound libraries are increasingly being used in computer-assisted drug discovery applications and have led to numerous successful cases. This paper aims to examine the fundamental concepts of library design and describe how to enumerate virtual libraries using open source tools. To exemplify the enumeration of chemical libraries, we emphasize the use of pre-validated or reported reactions and accessible chemical reagents. This tutorial shows a step-by-step procedure for anyone interested in designing and building chemical libraries with or without chemoinformatics experience. The aim is to explore various methodologies proposed by synthetic organic chemists and explore affordable chemical space using open-access chemoinformatics tools. As part of the tutorial, we discuss three examples of design: a Diversity-Oriented-Synthesis library based on lactams, a bis-heterocyclic combinatorial library, and a set of target-oriented molecules: isoindolinone based compounds as potential acetylcholinesterase inhibitors. This manuscript also seeks to contribute to the critical task of teaching and learning chemoinformatics.",
issn="1758-2946",
doi="10.1186/s13321-020-00466-z",
url="https://doi.org/10.1186/s13321-020-00466-z"
}

% ChEBI {{{3
@article{hastings2012_chebi,
	author = {Hastings, Janna and de Matos, Paula and Dekker, Adriano and Ennis, Marcus and Harsha, Bhavana and Kale, Namrata and Muthukrishnan, Venkatesh and Owen, Gareth and Turner, Steve and Williams, Mark and Steinbeck, Christoph},
	title = "{The ChEBI reference database and ontology for biologically relevant chemistry: enhancements for 2013}",
	journal = {Nucleic Acids Research},
	volume = {41},
	number = {D1},
	pages = {D456-D463},
	year = {2012},
	month = {11},
	abstract = "{ChEBI (http://www.ebi.ac.uk/chebi) is a database and ontology of chemical entities of biological interest. Over the past few years, ChEBI has continued to grow steadily in content, and has added several new features. In addition to incorporating all user-requested compounds, our annotation efforts have emphasized immunology, natural products and metabolites in many species. All database entries are now ‘is\_a’ classified within the ontology, meaning that all of the chemicals are available to semantic reasoning tools that harness the classification hierarchy. We have completely aligned the ontology with the Open Biomedical Ontologies (OBO) Foundry-recommended upper level Basic Formal Ontology. Furthermore, we have aligned our chemical classification with the classification of chemical-involving processes in the Gene Ontology (GO), and as a result of this effort, the majority of chemical-involving processes in GO are now defined in terms of the ChEBI entities that participate in them. This effort necessitated incorporating many additional biologically relevant compounds. We have incorporated additional data types including reference citations, and the species and component for metabolites. Finally, our website and web services have had several enhancements, most notably the provision of a dynamic new interactive graph-based ontology visualization.}",
	issn = {0305-1048},
	doi = {10.1093/nar/gks1146},
	url = {https://doi.org/10.1093/nar/gks1146},
	eprint = {https://academic.oup.com/nar/article-pdf/41/D1/D456/3646657/gks1146.pdf},
}

% COCONUT {{{3
% TOREAD
@article{sorokina2021_coconut,
	author="Sorokina, Maria and Merseburger, Peter and Rajan, Kohulan and Yirik, Mehmet Aziz and Steinbeck, Christoph",
	title="COCONUT online: Collection of Open Natural Products database",
	journal="Journal of Cheminformatics",
	year="2021",
	month="Jan",
	day="10",
	volume="13",
	number="1",
	pages="2",
	abstract="Natural products (NPs) are small molecules produced by living organisms with potential applications in pharmacology and other industries as many of them are bioactive. This potential raised great interest in NP research around the world and in different application fields, therefore, over the years a multiplication of generalistic and thematic NP databases has been observed. However, there is, at this moment, no online resource regrouping all known NPs in just one place, which would greatly simplify NPs research and allow computational screening and other in silico applications. In this manuscript we present the online version of the COlleCtion of Open Natural prodUcTs (COCONUT): an aggregated dataset of elucidated and predicted NPs collected from open sources and a web interface to browse, search and easily and quickly download NPs. COCONUT web is freely available at https://coconut.naturalproducts.net.",
	issn="1758-2946",
	doi="10.1186/s13321-020-00478-9",
	url="https://doi.org/10.1186/s13321-020-00478-9"
}

% H2V {{{3
% TOREAD
@article{zhou2021_h2v,
	author="Zhou, Nan and Bao, Jinku and Ning, Yuping",
	title="H2V: a database of human genes and proteins that respond to SARS-CoV-2, SARS-CoV, and MERS-CoV infection",
	journal="BMC Bioinformatics",
	year="2021",
	month="Jan",
	day="07",
	volume="22",
	number="1",
	pages="18",
	abstract="The ongoing global COVID-19 pandemic is caused by SARS-CoV-2, a novel coronavirus first discovered at the end of 2019. It has led to more than 50 million confirmed cases and more than 1 million deaths across 219 countries as of 11 November 2020, according to WHO statistics. SARS-CoV-2, SARS-CoV, and MERS-CoV are similar. They are highly pathogenic and threaten public health, impair the economy, and inflict long-term impacts on society. No drug or vaccine has been approved as a treatment for these viruses. Efforts to develop antiviral measures have been hampered by the insufficient understanding of how the human body responds to viral infections at the cellular and molecular levels.",
	issn="1471-2105",
	doi="10.1186/s12859-020-03935-2",
	url="https://doi.org/10.1186/s12859-020-03935-2"
}

% Propedia {{{3
% TOREAD
@article{martins2021_propedia,
	author="Martins, Pedro M. and Santos, Lucianna H. and Mariano, Diego and Queiroz, Felippe C. and Bastos, Luana L. and Gomes, Isabela de S. and Fischer, Pedro H. C. and Rocha, Rafael E. O. and Silveira, Sabrina A. and de Lima, Leonardo H. F. and de Magalh{\~a}es, Mariana T. Q. and Oliveira, Maria G. A. and de Melo-Minardi, Raquel C.",
	title="Propedia: a database for protein--peptide identification based on a hybrid clustering algorithm",
	journal="BMC Bioinformatics",
	year="2021",
	month="Jan",
	day="02",
	volume="22",
	number="1",
	pages="1",
	abstract="Protein--peptide interactions play a fundamental role in a wide variety of biological processes, such as cell signaling, regulatory networks, immune responses, and enzyme inhibition. Peptides are characterized by low toxicity and small interface areas; therefore, they are good targets for therapeutic strategies, rational drug planning and protein inhibition. Approximately 10{\%} of the ethical pharmaceutical market is protein/peptide-based. Furthermore, it is estimated that 40{\%} of protein interactions are mediated by peptides. Despite the fast increase in the volume of biological data, particularly on sequences and structures, there remains a lack of broad and comprehensive protein--peptide databases and tools that allow the retrieval, characterization and understanding of protein--peptide recognition and consequently support peptide design.",
	issn="1471-2105",
	doi="10.1186/s12859-020-03881-z",
	url="https://doi.org/10.1186/s12859-020-03881-z"
}

% KEGG {{{3
@article{kanehisa2000_kegg,
	author = {Kanehisa, Minoru and Goto, Susumu},
	title = "{KEGG: Kyoto Encyclopedia of Genes and Genomes}",
	journal = {Nucleic Acids Research},
	volume = {28},
	number = {1},
	pages = {27-30},
	year = {2000},
	month = {01},
	abstract = "{KEGG (Kyoto Encyclopedia of Genes and Genomes) is a knowledge base for systematic analysis of gene functions, linking genomic information with higher order functional information. The genomic information is stored in the GENES database, which is a collection of gene catalogs for all the completely sequenced genomes and some partial genomes with up-to-date annotation of gene functions. The higher order functional information is stored in the PATHWAY database, which contains graphical representations of cellular processes, such as metabolism, membrane transport, signal transduction and cell cycle. The PATHWAY database is supplemented by a set of ortholog group tables for the information about conserved subpathways (pathway motifs), which are often encoded by positionally coupled genes on the chromosome and which are especially useful in predicting gene functions. A third database in KEGG is LIGAND for the information about chemical compounds, enzyme molecules and enzymatic reactions. KEGG provides Java graphics tools for browsing genome maps, comparing two genome maps and manipulating expression maps, as well as computational tools for sequence comparison, graph comparison and path computation. The KEGG databases are daily updated and made freely available (http://www.genome.ad.jp/kegg/ ).}",
	issn = {0305-1048},
	doi = {10.1093/nar/28.1.27},
	url = {https://doi.org/10.1093/nar/28.1.27},
	eprint = {https://academic.oup.com/nar/article-pdf/28/1/27/9895154/280027.pdf},
}

% Search inside databases {{{2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Natural Language Descriptions of Phenotypes {{{3
% TOREAD
@article {Braun2021.02.04.429796,
	author = {Braun, Ian R. and Bassham, Diane C. and Lawrence-Dill, Carolyn J.},
	title = {The Case for Retaining Natural Language Descriptions of Phenotypes in Plant Databases and a Web Application as Proof of Concept},
	elocation-id = {2021.02.04.429796},
	year = {2021},
	doi = {10.1101/2021.02.04.429796},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {Motivation Finding similarity across phenotypic descriptions is not straightforward, with previous successes in computation requiring significant expert data curation. Natural language processing of free text phenotype descriptions is often easier to apply than intensive curation. It is therefore critical to understand the extent to which these techniques can be used to organize and analyze biological datasets and enable biological discoveries.Results A wide variety of approaches from the natural language processing domain perform as well as similarity metrics over curated annotations for predicting shared phenotypes. These approaches also show promise both for helping curators organize and work through large datasets as well as for enabling researchers to explore relationships among available phenotype descriptions. Here we generate networks of phenotype similarity and share a web application for querying a dataset of associated plant genes using these text mining approaches. Example situations and species for which application of these techniques is most useful are discussed.Availability The dataset used in this work is available at https://git.io/JTutQ. The code for the analysis performed here is available at https://git.io/JTutN and https://git.io/JTuqv. The code for the web application discussed here is available at https://git.io/Jtv9J, and the application itself is available at https://quoats.dill-picl.org/.Competing Interest StatementThe authors have declared no competing interest.},
	URL = {https://www.biorxiv.org/content/early/2021/02/06/2021.02.04.429796},
	eprint = {https://www.biorxiv.org/content/early/2021/02/06/2021.02.04.429796.full.pdf},
	journal = {bioRxiv}
}
% Clinical databases {{{2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% LabPipe {{{3
% Reading asked by Stanislas Grassin Delyle, Foch Hospital.
@article{zhao2020_labpipe,
	author="Zhao, Bo and Bryant, Luke and Cordell, Rebecca and Wilde, Michael and Salman, Dahlia and Ruszkiewicz, Dorota and Ibrahim, Wadah and Singapuri, Amisha and Coats, Tim and Gaillard, Erol and Beardsmore, Caroline and Suzuki, Toru and Ng, Leong and Greening, Neil and Thomas, Paul and Monks, Paul and Brightling, Christopher and Siddiqui, Salman and Free, Robert C.",
	title="LabPipe: an extensible bioinformatics toolkit to manage experimental data and metadata",
	journal="BMC Bioinformatics",
	year="2020",
	month="Dec",
	day="02",
	volume="21",
	number="1",
	pages="556",
	abstract="Data handling in clinical bioinformatics is often inadequate. No freely available tools provide straightforward approaches for consistent, flexible metadata collection and linkage of related experimental data generated locally by vendor software.",
	issn="1471-2105",
	doi="10.1186/s12859-020-03908-5",
	url="https://doi.org/10.1186/s12859-020-03908-5",
	note={Focus on collecting data and metadata across multiple sites. Server/client architecture, with plugins. Secure approach (SQL injection, DNS attacks, HTTPS, ...), good enough for anonymized data. Role-based authorizations. Based on Java 8 and MongoDB 4. Handle data \& metadata of instruments, but what about patient metadata? }
}

% Database cleaning {{{2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Principles and Methods of Data Cleaning: Primary Species and Species-Occurrence Data {{{3
% TOREAD
@techreport{chapman2005,
	author = {Chapman, A. D.},
	year = {2005},
	title = {Principles and Methods of Data Cleaning: Primary Species and Species-Occurrence Data, version 1.0},
	institution = {Global Biodiversity Information Facility, Copenhagen},
	url = {http://www.gbif.org/document/80528}
}

% Packages for accessing databases {{{2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% InterMineR: an R package for InterMine databases {{{3
% TOREAD
@article{kyritsis2019_InterMineR,
	author = {Kyritsis, Konstantinos A and Wang, Bing and Sullivan, Julie and Lyne, Rachel and Micklem, Gos},
	title = "{InterMineR: an R package for InterMine databases}",
	journal = {Bioinformatics},
	year = {2019},
	month = {01},
	abstract = "{InterMineR is a package designed to provide a flexible interface between the R programming environment and biological databases built using the InterMine platform. The package offers access to the flexible query builder and the library of term enrichment tools of the InterMine framework, as well as interoperability with other Bioconductor packages. This facilitates automation of data retrieval tasks as well as downstream analysis with existing statistical tools in the R environment.InterMineR is free and open source, released under the LGPL licence and available from the Bioconductor project and Github (https://bioconductor.org/packages/release/bioc/html/InterMineR.html, https://github.com/intermine/interMineR).Supplementary data are available at Bioinformatics online.}",
	issn = {1367-4803},
	doi = {10.1093/bioinformatics/btz039},
	url = {https://doi.org/10.1093/bioinformatics/btz039},
	eprint = {http://oup.prod.sis.lan/bioinformatics/advance-article-pdf/doi/10.1093/bioinformatics/btz039/27713167/btz039.pdf},
	note="See https://en.wikipedia.org/wiki/InterMine for the corresponding framework. Oriented toward genes and proteins."
}

% webchem: An R Package to Retrieve Chemical Information from the Web {{{3
% Chemical information from around the web. This package interacts with a suite of web APIs for chemical information. ChEBI, ChemSpider, NIST, PubChem, ... Targets retrieval of chemical data from web servers, and data cleaning. Developped to handle cleaning of toxic chemical compounds data. Limits request frequency. https://cran.r-project.org/web/packages/webchem/index.html.
@article{szocs2020_webchem,
	author = {Szöcs, Eduard and Stirling, Tamás and Scott, Eric and Scharmüller, Andreas and Schäfer, Ralf},
	year = {2020},
	month = {05},
	pages = {},
	title = {webchem : An R Package to Retrieve Chemical Information from the Web},
	volume = {93},
	journal = {Journal of statistical software},
	doi = {10.18637/jss.v093.i13},
	url = {https://www.researchgate.net/publication/341747373_webchem_An_R_Package_to_Retrieve_Chemical_Information_from_the_Web}
}

% ChemmineR: a compound mining framework for R {{{3
% NOTE ChemmineR vignette intro: http://www.bioconductor.org/packages/release/bioc/vignettes/ChemmineR/inst/doc/ChemmineR.html. Chemmine database (chemical genomics research): http://chemminedb.ucr.edu/.
@article{cao2008_ChemmineR,
	author = {Cao, Yiqun and Charisi, Anna and Cheng, Li-Chang and Jiang, Tao and Girke, Thomas},
	title = {ChemmineR: a compound mining framework for R},
	abstract = {Motivation: Software applications for structural similarity searching and clustering of small molecules play an important role in drug discovery and chemical genomics. Here, we present the first open-source compound mining framework for the popular statistical programming environment R. The integration with a powerful statistical environment maximizes the flexibility, expandability and programmability of the provided analysis functions.

Results: We discuss the algorithms and compound mining utilities provided by the R package ChemmineR. It contains functions for structural similarity searching, clustering of compound libraries with a wide spectrum of classification algorithms and various utilities for managing complex compound data. It also offers a wide range of visualization functions for compound clusters and chemical structures. The package is well integrated with the online ChemMine environment and allows bidirectional communications between the two services.

Availability: ChemmineR is freely available as an R package from the ChemMine project site: http://bioweb.ucr.edu/ChemMineV2/chemminer.},
	year = {2008},
	month = {08},
	volume = {24},
	number = {15},
	pages = {1733-1734},
	doi = {10.1093/bioinformatics/btn307}
}

% WikidataR {{{3
@misc{keys2017,
	author = {Keyes, Oliver and Signorelli, Serena and Graul, Christian and Popov, Mikhail},
	title = {WikidataR: API Client Library for Wikidata. R package version 1.4.0.},
	year = {2017},
	url = {https://CRAN.R-project.org/package=WikidataR}
}

% rpubchem package {{{3
% NOTE Package ‘rpubchem’ was removed from the CRAN repository. Archived on 2020-08-07 for policy violation. https://www.rdocumentation.org/packages/rpubchem/versions/1.5.10.
@misc{guha2016_rpubchem,
	author = {Guha, Rajarshi},
	year = {2016},
	title = {rpubchem: Interface to the PubChem Collection. R package version 1.5.10.},
	url = {https://CRAN.R-project.org/package=rpubchem}
}

% KEGGREST {{{3
@misc{tenenbaum2020_keggrest,
	author = {Tenenbaum, Dan and Volkening, Jeremy},
	year = {2020},
	title = {KEGGREST: Client-side REST access to the Kyoto Encyclopedia of Genes and Genomes (KEGG). R package version 1.30.1.},
	doi = {10.18129/B9.bioc.KEGGREST}
}

% hmdbQuery {{{3
@misc{carey2020_hmbdQuery,
	author = {Carey, Vince},
	year = {2020},
	title = {hmdbQuery: utilities for exploration of human metabolome database. R package version 1.10.0},
	doi = {10.18129/B9.bioc.hmdbQuery},
	note = {https://bioconductor.org/packages/release/bioc/html/hmdbQuery.html}
}

% UniProt.ws {{{3
@misc{carlson2020_uniprotws,
	author = {Carlson, Marc and Ortutay, Csaba},
	year = {2020},
	title = {UniProt.ws: R Interface to UniProt Web Services. R package version 2.30.0},
	doi = {10.18129/B9.bioc.UniProt.ws},
	notes = {https://bioconductor.org/packages/release/bioc/html/UniProt.ws.html}
}

% ChemSpider API {{{3
@misc{wolf2019_chemspiderapi,
	author = {Wolf, Raoul},
	year = {2019},
	title = {ChemSpider API R package},
	url = {https://github.com/NIVANorge/chemspiderapi}
}

% mirbase.db {{{3
@misc{reid2013_mirbasedb,
	author = {Reid, James F.},
	year = {2013},
	title = {mirbase.db: miRBase: the microRNA database. R package version 1.2.0},
	url = {http://bioconductor.org/packages/release/data/annotation/html/mirbase.db.html},
	doi = {10.18129/B9.bioc.mirbase.db}
}

% rentrez {{{3
% NOTE Access to NCBI Entrez database.
@misc{winter2020_rentrez,
	author = {Winter, David and Chamberlain, Scott and Guangchun, Han},
	year = {2020},
	title = {rentrez: 'Entrez' in R},
	url = {https://cran.r-project.org/web/packages/rentrez/}
}

% Biomartr {{{3
@article{drost2017_biomartr,
	author = {Drost, Hajk-Georg and Paszkowski, Jerzy},
	title = {Biomartr: genomic data retrieval with R},
	year = {2017},
	month = {4},
	journal = {Bioinformatics},
	volume = {33},
	number = {8},
	pages = {1216-1217},
    doi = {10.1093/bioinformatics/btw821}
}

% RMassBank {{{3
@article{stravs2013_rmassbank,
	author = {Stravs, Michael A. and Schymanski, Emma L. and Singer, Heinz P. and Hollender, Juliane},
	title = {Automatic recalibration and processing of tandem mass spectra using formula annotation},
	journal = {Journal of Mass Spectrometry},
	year = {2013},
	volume = {48},
	number = {1},
	pages = {89-99},
	doi = {https://doi.org/10.1002/jms.3131},
	keywords = {mass spectrometry, recalibration, Orbitrap, molecular formula, mass spectra libraries},
	doi = {https://doi.org/10.1002/jms.3131},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jms.3131},
	eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/jms.3131},
	abstract = {High accuracy, high resolution tandem mass spectrometry (MS/MS) is becoming more common in analytical applications, yet databases of these spectra remain limited. Databases require good quality spectra with sufficient compound information, but processing, calibration, noise reduction and retrieval of compound information are time-consuming tasks that prevent many contributions. We present a comprehensive workflow for the automatic processing of MS/MS using formula annotation for recalibration and cleanup to generate high quality spectra of standard compounds for upload to MassBank (www.massbank.jp). Compound information is retrieved via Internet services. Reference standards of 70 pesticides were measured at various collision energies on an LTQ-Orbitrap XL to develop and evaluate the workflow. A total of 944 resulting spectra are now available on MassBank. Evidence of nitrogen adduct formation during MS/MS fragmentation processes was found, highlighting the benefits high accuracy MS/MS offers for spectral interpretation. A database of recalibrated, cleaned-up spectra resulted in the most correct spectra ranked in first place, regardless of whether the search spectra were recalibrated or not, whereas the average rank of the correct molecular formula was improved from 2.55 (uncalibrated) to 1.53 when using recalibrated MS/MS data. The workflow is available as an R package RMassBank capable of generating MassBank records from raw MS and MS/MS data and can be adjusted to process data acquired with different settings and instruments. This workflow is a vital step towards addressing the need for more high quality, high accuracy MS/MS spectra in spectral databases and provides important information for spectral interpretation. Copyright © 2012 John Wiley \& Sons, Ltd.},
	note = {https://bioconductor.org/packages/release/bioc/html/RMassBank.html}
}


% UniprotR {{{3
% TOREAD
@article{soudy2020_uniprotr,
title = "UniprotR: Retrieving and visualizing protein sequence and functional information from Universal Protein Resource (UniProt knowledgebase)",
journal = "Journal of Proteomics",
volume = "213",
pages = "103613",
year = "2020",
issn = "1874-3919",
doi = "https://doi.org/10.1016/j.jprot.2019.103613",
url = "http://www.sciencedirect.com/science/article/pii/S1874391919303859",
author = "Mohamed Soudy and Ali Mostafa Anwar and Eman Ali Ahmed and Aya Osama and Shahd Ezzeldin and Sebaey Mahgoub and Sameh Magdeldin",
keywords = "Proteomics, UniProtKB, UniProt, Bioinformatics, R package",
abstract = "UniprotR is a software package designed to easily retrieve, cluster and visualize protein data from UniProt knowledgebase (UniProtKB) using R language. The package is implemented mainly to process, parse and illustrate proteomics data in a handy and time-saving approach allowing researchers to summarize all required protein information available at UniProtKB in a readable data frame, Excel CSV file, and/or graphical output. UniprotR generates a set of graphics including gene ontology, chromosomal location, protein scoring and status, protein networking, sequence phylogenetic tree, and physicochemical properties. In addition, the package supports clustering of proteins based on primary gene name or chromosomal location, facilitating additional downstream analysis.
Significance
In this work, we implemented a robust package for retrieving and visualizing information from multiple sources such UniProtKB, SWISS-MODEL, and STRING. UniprotR Contains functions that enable retrieving and cluster data in a handy way and visualize data in publishable graphs to facilitate researcher's work and fulfill their needs. UniprotR will aid in saving time for downstream data analysis instead of manual time consuming data analysis.
Availability and implementation
UniprotR released as free open source code under the license of GPLv3, and available in CRAN (The Comprehensive R Archive Network) and GitHub. (https://cran.r-project.org/web/packages/UniprotR/index.html). (https://github.com/Proteomicslab57357/UniprotR)."
}

% Pathview: an R/Bioconductor package for pathway-based data integration and visualization {{{3
% TOREAD
@article{luo2013_pathview,
    author = {Luo, Weijun and Brouwer, Cory},
    title = "{Pathview: an R/Bioconductor package for pathway-based data integration and visualization}",
    journal = {Bioinformatics},
    volume = {29},
    number = {14},
    pages = {1830-1831},
    year = {2013},
    month = {06},
    abstract = "{Summary: Pathview is a novel tool set for pathway-based data integration and visualization. It maps and renders user data on relevant pathway graphs. Users only need to supply their data and specify the target pathway. Pathview automatically downloads the pathway graph data, parses the data file, maps and integrates user data onto the pathway and renders pathway graphs with the mapped data. Although built as a stand-alone program, Pathview may seamlessly integrate with pathway and functional analysis tools for large-scale and fully automated analysis pipelines.Availability: The package is freely available under the GPLv3 license through Bioconductor and R-Forge. It is available at http://bioconductor.org/packages/release/bioc/html/pathview.html and at http://Pathview.r-forge.r-project.org/.Contact:luo\_weijun@yahoo.comSupplementary information:Supplementary data are available at Bioinformatics online.}",
    issn = {1367-4803},
    doi = {10.1093/bioinformatics/btt285},
    url = {https://doi.org/10.1093/bioinformatics/btt285},
    eprint = {https://academic.oup.com/bioinformatics/article-pdf/29/14/1830/16916584/btt285.pdf},
    note = {
http://pathview.r-forge.r-project.org/
http://www.bioconductor.org/packages/release/bioc/html/pathview.html
https://doi.org/doi:10.18129/B9.bioc.pathview
https://academic.oup.com/bioinformatics/article/29/14/1830/232698
    }
}

% Bioinformatics: The Next Frontier of Metabolomics {{{2
@article{johnson2015,
	author = {Johnson, Caroline H. and Ivanisevic, Julijana and Benton, H. Paul and Siuzdak, Gary},
	title = {Bioinformatics: The Next Frontier of Metabolomics},
	journal = {Analytical Chemistry},
	pages = {147-156},
	year = {2015},
	month = "11",
	volume = "87",
	number = "1",
	doi = {10.1021/ac5040693},
	eprint = "http://pubs.acs.org/doi/pdf/10.1021/ac5040693",
	url = "http://pubs.acs.org/doi/abs/10.1021/ac5040693"
}

% An integrated clinical and genomic information system for cancer precision medicine {{{2
@article{jang2018_integrated_clinical_and_genomic,
	author="Jang, Yeongjun and Choi, Taekjin and Kim, Jongho and Park, Jisub and Seo, Jihae and Kim, Sangok and Kwon, Yeajee and Lee, Seungjae and Lee, Sanghyuk",
	title="An integrated clinical and genomic information system for cancer precision medicine",
	journal="BMC Medical Genomics",
	year="2018",
	month="4",
	day="20",
	volume="11",
	number="2",
	pages="34",
	abstract="Increasing affordability of next-generation sequencing (NGS) has created an opportunity for realizing genomically-informed personalized cancer therapy as a path to precision oncology. However, the complex nature of genomic information presents a huge challenge for clinicians in interpreting the patient's genomic alterations and selecting the optimum approved or investigational therapy. An elaborate and practical information system is urgently needed to support clinical decision as well as to test clinical hypotheses quickly.",
	issn="1755-8794",
	doi="10.1186/s12920-018-0347-9",
	url="https://doi.org/10.1186/s12920-018-0347-9",
	note={CGIS software to provide useful information for both clinicians and scientists who want to explore genomic information for precision oncology. Built their own database BioDataBank, from Entrez genes, Uniprot and others. Drugs from text mining in all the PubMed abstracts using a machine learning method. Survival analysis of resulting patient groups can be carried out interactively to facilitate hypothesis test of survival benefit for clinicians.}
}

% Inferring Interaction Networks From Multi-Omics Data {{{2
% TOREAD
@article{hawe2019,
	AUTHOR={Hawe, Johann S. and Theis, Fabian J. and Heinig, Matthias},   
	TITLE={Inferring Interaction Networks From Multi-Omics Data},      
	JOURNAL={Frontiers in Genetics},      
	VOLUME={10},      
	PAGES={535},     
	YEAR={2019},      
	URL={https://www.frontiersin.org/article/10.3389/fgene.2019.00535},       
	DOI={10.3389/fgene.2019.00535},      
	ISSN={1664-8021},   
	ABSTRACT={A major goal in systems biology is a comprehensive description the entirety of all complex interactions between different types of biomolecules - also referred to as the interactome - and how these interactions give rise to higher, cellular and organism level functions or diseases.
		Numerous efforts have been undertaken to define such interactomes experimentally, for example yeast-tow-hybrid based protein-protein interaction networks or ChIP-seq based protein-DNA interactions for individual proteins.
			To complement these direct measurements, genome-scale quantitative multi-omics data (proteomics, transcriptomics, etc.)  enable researchers to predict novel functional interactions between molecular species.
			Moreover, these data allow to distinguish relevant functional from non-functional interactions in a specific biological context. 
			However, integration of multi-omics data is not straight forward due to their heterogeneity.
			So far, interaction networks have mostly been inferred from homogeneous functional data (e.g. gene co-expression networks) and novel methods are essential for inferring comprehensive regulatory networks across omics data types.

			Here we review state-of-the-art techniques for inferring the topology of interaction networks from functional multi-omics data, encompassing graphical models with multiple node types and quantitative-trait-loci (QTL) based approaches. 
			In addition, we will discuss Bayesian aspects of network inference, which allow for leveraging already established biological information, such as known protein-protein or protein-DNA interactions, to guide the inference process.}
}


% ISA API: An open platform for interoperable life science experimental metadata {{{2
@article {johnson2020,
	author = {Johnson, David and Cochrane, Keeva and Davey, Robert P and Etuk, Anthony and Gonzalez-Beltran, Alejandra and Haug, Kenneth and Izzo, Massimiliano and Larralde, Martin and Lawson, Thomas N and Minotto, Alice and Moreno, Pablo and Nainala, Venkata Chandrasekhar and O{\textquoteright}Donovan, Claire and Pireddu, Luca and Roger, Pierrick and Shaw, Felix and Steinbeck, Christoph and Weber, Ralf JM and Sansone, Susanna-Assunta and Rocca-Serra, Philippe},
	title = {ISA API: An open platform for interoperable life science experimental metadata},
	elocation-id = {2020.11.13.382119},
	year = {2020},
	doi = {10.1101/2020.11.13.382119},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {Background: The Investigation/Study/Assay (ISA) Metadata Framework is an established and widely used set of open-source community specifications and software tools for enabling discovery, exchange and publication of metadata from experiments in the life sciences. The original ISA software suite provided a set of user-facing Java tools for creating and manipulating the information structured in ISA-Tab - a now widely used tabular format. To make the ISA framework more accessible to machines and enable programmatic manipulation of experiment metadata, a JSON serialization ISA-JSON was developed. Results: In this work, we present the ISA API, a Python library for the creation, editing, parsing, and validating of ISA-Tab and ISA-JSON formats by using a common data model engineered as Python class objects. We describe the ISA API feature set, early adopters and its growing user community. Conclusions: The ISA API provides users with rich programmatic metadata handling functionality to support automation, a common interface and an interoperable medium between the two ISA formats, as well as with other life science data formats required for depositing data in public databases.Competing Interest StatementThe authors have declared no competing interest.},
	URL = {https://www.biorxiv.org/content/early/2020/11/16/2020.11.13.382119},
	eprint = {https://www.biorxiv.org/content/early/2020/11/16/2020.11.13.382119.full.pdf},
	journal = {bioRxiv}
}
% BioUML: an integrated environment for systems biology and collaborative analysis of biomedical data {{{2
% TOREAD
@article{kolpakov2019_BioUML,
	author = {Kolpakov, Fedor and Akberdin, Ilya and Kashapov, Timur and Kiselev, llya and Kolmykov, Semyon and Kondrakhin, Yury and Kutumova, Elena and Mandrik, Nikita and Pintus, Sergey and Ryabova, Anna and Sharipov, Ruslan and Yevshin, Ivan and Kel, Alexander},
	title = "{BioUML: an integrated environment for systems biology and collaborative analysis of biomedical data}",
	journal = {Nucleic Acids Research},
	volume = {47},
	number = {W1},
	pages = {W225-W233},
	year = {2019},
	month = {05},
	abstract = "{BioUML (homepage: http://www.biouml.org, main public server: https://ict.biouml.org) is a web-based integrated environment (platform) for systems biology and the analysis of biomedical data generated by omics technologies. The BioUML vision is to provide a computational platform to build virtual cell, virtual physiological human and virtual patient. BioUML spans a comprehensive range of capabilities, including access to biological databases, powerful tools for systems biology (visual modelling, simulation, parameters fitting and analyses), a genome browser, scripting (R, JavaScript) and a workflow engine. Due to integration with the Galaxy platform and R/Bioconductor, BioUML provides powerful possibilities for the analyses of omics data. The plug-in-based architecture allows the user to add new functionalities using plug-ins. To facilitate a user focus on a particular task or database, we have developed several predefined perspectives that display only those web interface elements that are needed for a specific task. To support collaborative work on scientific projects, there is a central authentication and authorization system (https://bio-store.org). The diagram editor enables several remote users to simultaneously edit diagrams.}",
	issn = {0305-1048},
	doi = {10.1093/nar/gkz440},
	url = {https://doi.org/10.1093/nar/gkz440},
	eprint = {http://oup.prod.sis.lan/nar/article-pdf/47/W1/W225/28879921/gkz440.pdf},
}

% ClassyFire: automated chemical classification with a comprehensive, computable taxonomy {{{2
% TOREAD
@Article{DjoumbouFeunang2016,
	author="Djoumbou Feunang, Yannick
		and Eisner, Roman
		and Knox, Craig
		and Chepelev, Leonid
		and Hastings, Janna
		and Owen, Gareth
		and Fahy, Eoin
		and Steinbeck, Christoph
		and Subramanian, Shankar
		and Bolton, Evan
		and Greiner, Russell
		and Wishart, David S.",
	title="ClassyFire: automated chemical classification with a comprehensive, computable taxonomy",
	journal="Journal of Cheminformatics",
	year="2016",
	month="11",
	day="04",
	volume="8",
	number="1",
	pages="61",
	abstract="Scientists have long been driven by the desire to describe, organize, classify, and compare objects using taxonomies and/or ontologies. In contrast to biology, geology, and many other scientific disciplines, the world of chemistry still lacks a standardized chemical ontology or taxonomy. Several attempts at chemical classification have been made; but they have mostly been limited to either manual, or semi-automated proof-of-principle applications. This is regrettable as comprehensive chemical classification and description tools could not only improve our understanding of chemistry but also improve the linkage between chemistry and many other fields. For instance, the chemical classification of a compound could help predict its metabolic fate in humans, its druggability or potential hazards associated with it, among others. However, the sheer number (tens of millions of compounds) and complexity of chemical structures is such that any manual classification effort would prove to be near impossible.",
	issn="1758-2946",
	doi="10.1186/s13321-016-0174-y",
	url="https://doi.org/10.1186/s13321-016-0174-y"
}

% Matching and annotation {{{2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Improving MetFrag with statistical learning of fragment annotations {{{3
% TOREAD
@Article{ruttkies2019,
	author="Ruttkies, Christoph and Neumann, Steffen and Posch, Stefan",
	title="Improving MetFrag with statistical learning of fragment annotations",
	journal="BMC Bioinformatics",
	year="2019",
	month="07",
	day="05",
	volume="20",
	number="376",
	abstract="Molecule identification is a crucial step in metabolomics and environmental sciences. Besides in silico fragmentation, as performed by MetFrag, also machine learning and statistical methods evolved, showing an improvement in molecule annotation based on MS/MS data. In this work we present a new statistical scoring method where annotations of m/z fragment peaks to fragment-structures are learned in a training step. Based on a Bayesian model, two additional scoring terms are integrated into the new MetFrag2.4.5 and evaluated on the test data set of the CASMI 2016 contest.",
	issn="1471-2105",
	url="https://doi.org/10.1186/s12859-019-2954-7",
	doi="10.1186/s12859-019-2954-7"
}

% Galaxy, W4M & other workflow systems {{{2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% W4M 2017 {{{3
@article{guitton2017,
title = "Create, run, share, publish, and reference your LC–MS, FIA–MS, GC–MS, and NMR data analysis workflows with the Workflow4Metabolomics 3.0 Galaxy online infrastructure for metabolomics",
journal = {The International Journal of Biochemistry \& Cell Biology},
volume = "93",
pages = "89 - 101",
year = "2017",
issn = "1357-2725",
doi = "https://doi.org/10.1016/j.biocel.2017.07.002",
url = "http://www.sciencedirect.com/science/article/pii/S1357272517301577",
author = "Yann Guitton and Marie Tremblay-Franco and Gildas {Le Corguillé} and Jean-François Martin and Mélanie Pétéra and Pierrick Roger-Mele and Alexis Delabrière and Sophie Goulitquer and Misharl Monsoor and Christophe Duperier and Cécile Canlet and Rémi Servien and Patrick Tardivel and Christophe Caron and Franck Giacomoni and Etienne A. Thévenot",
keywords = "Metabolomics, Data analysis, E-infrastructure, Workflow, Galaxy, Repository",
abstract = "Metabolomics is a key approach in modern functional genomics and systems biology. Due to the complexity of metabolomics data, the variety of experimental designs, and the multiplicity of bioinformatics tools, providing experimenters with a simple and efficient resource to conduct comprehensive and rigorous analysis of their data is of utmost importance. In 2014, we launched the Workflow4Metabolomics (W4M; http://workflow4metabolomics.org) online infrastructure for metabolomics built on the Galaxy environment, which offers user-friendly features to build and run data analysis workflows including preprocessing, statistical analysis, and annotation steps. Here we present the new W4M 3.0 release, which contains twice as many tools as the first version, and provides two features which are, to our knowledge, unique among online resources. First, data from the four major metabolomics technologies (i.e., LC–MS, FIA–MS, GC–MS, and NMR) can be analyzed on a single platform. By using three studies in human physiology, alga evolution, and animal toxicology, we demonstrate how the 40 available tools can be easily combined to address biological issues. Second, the full analysis (including the workflow, the parameter values, the input data and output results) can be referenced with a permanent digital object identifier (DOI). Publication of data analyses is of major importance for robust and reproducible science. Furthermore, the publicly shared workflows are of high-value for e-learning and training. The Workflow4Metabolomics 3.0 e-infrastructure thus not only offers a unique online environment for analysis of data from the main metabolomics technologies, but it is also the first reference repository for metabolomics workflows."
}

% Ontologies {{{2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% OntoMaton: a Bioportal powered ontology widget for Google Spreadsheets {{{3
% TOREAD
@article{maguire2012,
	author = {Maguire, Eamonn and González-Beltrán, Alejandra and Whetzel, Patricia L. and Sansone, Susanna-Assunta and Rocca-Serra, Philippe},
	title = "{OntoMaton: a Bioportal powered ontology widget for Google Spreadsheets}",
	journal = {Bioinformatics},
	volume = {29},
	number = {4},
	pages = {525-527},
	year = {2012},
	month = {12},
	abstract = "{Motivation: Data collection in spreadsheets is ubiquitous, but current solutions lack support for collaborative semantic annotation that would promote shared and interdisciplinary annotation practices, supporting geographically distributed players.Results: OntoMaton is an open source solution that brings ontology lookup and tagging capabilities into a cloud-based collaborative editing environment, harnessing Google Spreadsheets and the NCBO Web services. It is a general purpose, format-agnostic tool that may serve as a component of the ISA software suite. OntoMaton can also be used to assist the ontology development process.Availability: OntoMaton is freely available from Google widgets under the CPAL open source license; documentation and examples at: https://github.com/ISA-tools/OntoMaton.Contact:isatools@googlegroups.com}",
	issn = {1367-4803},
	doi = {10.1093/bioinformatics/bts718},
	url = {https://doi.org/10.1093/bioinformatics/bts718},
	eprint = {http://oup.prod.sis.lan/bioinformatics/article-pdf/29/4/525/504231/bts718.pdf},
}

% The Stem Cell Discovery Engine: an integrated repository and analysis system for cancer stem cell comparisons {{{3
% TOREAD
@article{hosui2011,
	author = {Ho Sui, Shannan J. and Begley, Kimberly and Reilly, Dorothy and Chapman, Brad and McGovern, Ray and Rocca-Sera, Philippe and Maguire, Eamonn and Altschuler, Gabriel M. and Hansen, Terah A. A. and Sompallae, Ramakrishna and Krivtsov, Andrei and Shivdasani, Ramesh A. and Armstrong, Scott A. and Culhane, Aedín C. and Correll, Mick and Sansone, Susanna-Assunta and Hofmann, Oliver and Hide, Winston},
	title = "{The Stem Cell Discovery Engine: an integrated repository and analysis system for cancer stem cell comparisons}",
	journal = {Nucleic Acids Research},
	volume = {40},
	number = {D1},
	pages = {D984-D991},
	year = {2011},
	month = {11},
	abstract = "{Mounting evidence suggests that malignant tumors are initiated and maintained by a subpopulation of cancerous cells with biological properties similar to those of normal stem cells. However, descriptions of stem-like gene and pathway signatures in cancers are inconsistent across experimental systems. Driven by a need to improve our understanding of molecular processes that are common and unique across cancer stem cells (CSCs), we have developed the Stem Cell Discovery Engine (SCDE)—an online database of curated CSC experiments coupled to the Galaxy analytical framework. The SCDE allows users to consistently describe, share and compare CSC data at the gene and pathway level. Our initial focus has been on carefully curating tissue and cancer stem cell-related experiments from blood, intestine and brain to create a high quality resource containing 53 public studies and 1098 assays. The experimental information is captured and stored in the multi-omics Investigation/Study/Assay (ISA-Tab) format and can be queried in the data repository. A linked Galaxy framework provides a comprehensive, flexible environment populated with novel tools for gene list comparisons against molecular signatures in GeneSigDB and MSigDB, curated experiments in the SCDE and pathways in WikiPathways. The SCDE is available at http://discovery.hsci.harvard.edu.}",
	issn = {0305-1048},
	doi = {10.1093/nar/gkr1051},
	url = {https://doi.org/10.1093/nar/gkr1051},
	eprint = {http://oup.prod.sis.lan/nar/article-pdf/40/D1/D984/16954376/gkr1051.pdf},
}

% Toward interoperable bioscience data {{{3
% TOREAD
@article{Sansone2012,
	author = {Sansone, Susanna-Assunta and Rocca-Serra, Philippe and Field, Dawn and Maguire, Eamonn and Taylor, Chris and Hofmann, Oliver and Fang, Hong and Neumann, Steffen and Tong, Weida and Amaral-Zettler, Linda and Begley, Kimberly and Booth, Tim and Bougueleret, Lydie and Burns, Gully and Chapman, Brad and Clark, Tim and Coleman, Lee-Ann and Copeland, Jay and Das, Sudeshna and de Daruvar, Antoine and de Matos, Paula and Dix, Ian and Edmunds, Scott and Evelo, Chris T and Forster, Mark J and Gaudet, Pascale and Gilbert, Jack and Goble, Carole and Griffin, Julian L and Jacob, Daniel and Kleinjans, Jos and Harland, Lee and Haug, Kenneth and Hermjakob, Henning and Sui, Shannan J Ho and Laederach, Alain and Liang, Shaoguang and Marshall, Stephen and McGrath, Annette and Merrill, Emily and Reilly, Dorothy and Roux, Magali and Shamu, Caroline E and Shang, Catherine A and Steinbeck, Christoph and Trefethen, Anne and Williams-Jones, Bryn and Wolstencroft, Katherine and Xenarios, Ioannis and Hide, Winston},
	title = "Toward interoperable bioscience data",
	journal = "Nature Genetics",
	volume = {44},
	pages = {121-126},
	year = {2012},
	month = {1},
	abstract = "{To make full use of research data, the bioscience community needs to adopt technologies and reward mechanisms that support interoperability and promote the growth of an open ‘data commoning’ culture. Here we describe the prerequisites for data commoning and present an established and growing ecosystem of solutions using the shared ‘Investigation-Study-assay’ framework to support that vision.}",
	url = {https://doi.org/10.1038/ng.1054},
	doi = {10.1038/ng.1054},
	eprint = {https://www.nature.com/articles/ng.1054.pdf}
}

% Energy & building {{{1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% GRENAD, a Modular and Generic Smart-Grid Framework {{{2
@inproceedings{ductor2015_grenad,
  title = {GRENAD, a Modular and Generic Smart-Grid Framework},
  author = {Ductor, Sylvain and Gil-Quijano, Javier and Stefanovitch, Nicolas and Mele, Pierrick Roger},
  url = {https://hal.archives-ouvertes.fr/hal-01912158},
  note = {ISSN 2300-5963},
  booktitle = {{2015 Federated Conference on Computer Science and Information Systems}},
  address = {Ł{\'o}d{\'z}, Poland},
  series = {Proceedings of the 2015 Federated Conference on Computer Science and Information Systems},
  volume = {5},
  pages = {pp. 1781--1792},
  year = {2015},
  month = Sep,
  doi = {10.15439/2015F310},
  keywords = {agent model ; smart grid model ; Controllability ; smart grid ; multi-agent system (MAS) ; electricity grid ; modular ; components ; functionalities ; energy ; controllable ; interface ; simulator ; energy supply ; JADE language ; JADE agents ; Internal physical constraints ; Virtual Power Plant},
  HAL_ID = {hal-01912158},
  HAL_VERSION = {v1},
}

% TO SORT {{{1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article {freedman2020.05.12.091223,
	author = {Freedman, Hayden G. and Williams, Heather and Miller, Mark A. and Birtwell, David and Mowery, Danielle L. and Stoeckert, Christian J.},
	title = {A novel tool for standardizing clinical data in a realism-based common data model},
	elocation-id = {2020.05.12.091223},
	year = {2020},
	doi = {10.1101/2020.05.12.091223},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {Standardizing clinical information in a common data model is important for promoting interoperability and facilitating high quality research. Semantic Web technologies such as Resource Description Framework can be utilized to their full potential when a clinical data model accurately reflects the reality of the clinical situation it describes. To this end, the Open Biomedical Ontologies Foundry provides a set of ontologies that conform to the principles of realism and can be used to create a realism-based clinical data model. However, the challenge of programmatically defining such a model and loading data from disparate sources into the model has not been addressed by pre-existing software solutions. The PennTURBO Semantic Engine is a tool developed at the University of Pennsylvania that works in conjunction with data aggregation software to transform source-specific RDF data into a source-independent, realism-based data model. This system sources classes from an application ontology and specifically defines how instances of those classes may relate to each other. Additionally, the system defines and executes RDF data transformations by launching dynamically generated SPARQL update statements. The Semantic Engine was designed as a generalizable RDF data standardization tool, and is able to work with various data models and incoming data sources. Its human-readable configuration files can easily be shared between institutions, providing the basis for collaboration on a standard realism-based clinical data model.Competing Interest StatementThe authors have declared no competing interest.},
	URL = {https://www.biorxiv.org/content/early/2020/05/14/2020.05.12.091223},
	eprint = {https://www.biorxiv.org/content/early/2020/05/14/2020.05.12.091223.full.pdf},
	journal = {bioRxiv}
}

@article {slater2020.05.16.099309,
	author = {Slater, Luke T and Gkoutos, Georgios V and Hoehndorf, Robert},
	title = {Towards semantic interoperability: finding and repairing hidden contradictions in biomedical ontologies},
	elocation-id = {2020.05.16.099309},
	year = {2020},
	doi = {10.1101/2020.05.16.099309},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {Background Ontologies are widely used throughout the biomedical domain. These ontologies formally represent the classes and relations assumed to exist within a domain. As scientific domains are deeply interlinked, so too are their representations. While individual ontologies can be tested for consistency and coherency using automated reasoning methods, systematically combining ontologies of multiple domains together may reveal previously hidden contradictions.Results We developed a method that tests for hidden unsatisfiabilities in an ontology that arise when combined with other ontologies. For this purpose, we combine sets of ontologies and use automated reasoning to determine whether unsatisfiable classes are present. We test the mutual consistency of the OBO Foundry and the OBO ontologies and find that the combined OBO Foundry gives rise to at least 636 unsatisfiable classes, while the OBO ontologies give rise to more than 300,000 unsatisfiable classes.We design and implement a novel algorithm that can determine justifications for contradictions across extremely large and complicated ontologies, and use these justifications to semi-automatically repair ontologies by identifying the minimal set of axioms that, when removed, result in a consistent and coherent set of ontologies. We applied our algorithm to each combination of OBO ontologies that resulted in unsatisfiable classes.Conclusions We identified a large set of hidden unsatisfiability across a broad range of biomedical ontologies, and we find that this large set of unsatisfiable classes is the result of a relatively small amount of axiomatic disagreements. Our results show that hidden unsatisfiability is a serious problem in ontology interoperability; however, our results also provide a way towards more consistent ontologies by addressing the issues we identified.Competing Interest StatementThe authors have declared no competing interest.},
	URL = {https://www.biorxiv.org/content/early/2020/05/17/2020.05.16.099309},
	eprint = {https://www.biorxiv.org/content/early/2020/05/17/2020.05.16.099309.full.pdf},
	journal = {bioRxiv}
}

@article{vansanten2019,
	author={van Santen, Jeffrey A. and Jacob, Gr{\'e}goire and Singh, Amrit Leen and Aniebok, Victor and Balunas, Marcy J. and Bunsko, Derek and Neto, Fausto Carnevale and Casta{\~{n}}o-Espriu, Laia and Chang, Chen and Clark, Trevor N. and Cleary Little, Jessica L. and Delgadillo, David A. and Dorrestein, Pieter C. and Duncan, Katherine R. and Egan, Joseph M. and Galey, Melissa M. and Haeckl, F.P. Jake and Hua, Alex and Hughes, Alison H. and Iskakova, Dasha and Khadilkar, Aswad and Lee, Jung-Ho and Lee, Sanghoon and LeGrow, Nicole and Liu, Dennis Y. and Macho, Jocelyn M. and McCaughey, Catherine S. and Medema, Marnix H. and Neupane, Ram P. and O'Donnell, Timothy J. and Paula, Jasmine S. and Sanchez, Laura M. and Shaikh, Anam F. and Soldatou, Sylvia and Terlouw, Barbara R. and Tran, Tuan Anh and Valentine, Mercia and van der Hooft, Justin J. J. and Vo, Duy A. and Wang, Mingxun and Wilson, Darryl and Zink, Katherine E. and Linington, Roger G.",
	title="The Natural Products Atlas: An Open Access Knowledge Base for Microbial Natural Products Discovery},
	journal="ACS Central Science",
	year="2019",
	month="Nov",
	day="27",
	publisher="American Chemical Society",
	volume="5",
	number="11",
	pages="1824--1833",
	issn="2374-7943",
	doi="10.1021/acscentsci.9b00806",
	url="https://doi.org/10.1021/acscentsci.9b00806"
}

@Article{hernandezdediego2014_STATegra,
author="Hern{\'a}ndez-de-Diego, Rafael
and Boix-Chova, Noemi
and G{\'o}mez-Cabrero, David
and Tegner, Jesper
and Abugessaisa, Imad
and Conesa, Ana",
title="STATegra EMS: an Experiment Management System for complex next-generation omics  experiments.",
journal="BMC systems biology",
year="2014",
volume="8 Suppl 2",
number="Suppl 2",
pages="S9",
keywords="Computational Biology/*methods; *High-Throughput Nucleotide Sequencing; Humans; Metabolomics; Proteomics; Software; Statistics as Topic",
abstract="High-throughput sequencing assays are now routinely used to study different aspects  of genome organization. As decreasing costs and widespread availability of  sequencing enable more laboratories to use sequencing assays in their research  projects, the number of samples and replicates in these experiments can quickly grow  to several dozens of samples and thus require standardized annotation, storage and  management of preprocessing steps. As a part of the STATegra project, we have  developed an Experiment Management System (EMS) for high throughput omics data that  supports different types of sequencing-based assays such as RNA-seq, ChIP-seq,  Methyl-seq, etc, as well as proteomics and metabolomics data. The STATegra EMS  provides metadata annotation of experimental design, samples and processing  pipelines, as well as storage of different types of data files, from raw data to  ready-to-use measurements. The system has been developed to provide research  laboratories with a freely-available, integrated system that offers a simple and  effective way for experiment annotation and tracking of analysis procedures.",
doi="10.1186/1752-0509-8-S2-S9",
url="https://doi.org/10.1186/1752-0509-8-S2-S9",
url="http://www.ncbi.nlm.nih.gov/pubmed/25033091",
url="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4101697",
language="eng"
}

@article{djoumboufeunang2016_ClassyFire,
author="Djoumbou Feunang, Yannick
and Eisner, Roman
and Knox, Craig
and Chepelev, Leonid
and Hastings, Janna
and Owen, Gareth
and Fahy, Eoin
and Steinbeck, Christoph
and Subramanian, Shankar
and Bolton, Evan
and Greiner, Russell
and Wishart, David S.",
title="ClassyFire: automated chemical classification with a comprehensive, computable taxonomy",
journal="Journal of Cheminformatics",
year="2016",
month="Nov",
day="04",
volume="8",
number="1",
pages="61",
abstract="Scientists have long been driven by the desire to describe, organize, classify, and compare objects using taxonomies and/or ontologies. In contrast to biology, geology, and many other scientific disciplines, the world of chemistry still lacks a standardized chemical ontology or taxonomy. Several attempts at chemical classification have been made; but they have mostly been limited to either manual, or semi-automated proof-of-principle applications. This is regrettable as comprehensive chemical classification and description tools could not only improve our understanding of chemistry but also improve the linkage between chemistry and many other fields. For instance, the chemical classification of a compound could help predict its metabolic fate in humans, its druggability or potential hazards associated with it, among others. However, the sheer number (tens of millions of compounds) and complexity of chemical structures is such that any manual classification effort would prove to be near impossible.",
issn="1758-2946",
doi="10.1186/s13321-016-0174-y",
url="https://doi.org/10.1186/s13321-016-0174-y"
}

@article{hawe2019_networks,
	author = {Hawe, JS and Theis, FJ and Heinig, M},
	year = {2019},
	title = {Inferring Interaction Networks From Multi-Omics Data.}
	journal = {frontiers in Genetics},
	volume = {10},
	pages = {535},
	doi = {10.3389/fgene.2019.00535},
	url = {https://www.frontiersin.org/articles/10.3389/fgene.2019.00535/full}
}

@article{hornung2019_block_forests,
	author="Hornung, Roman and Wright, Marvin N.",
	title="Block Forests: random forests for blocks of clinical and omics covariate data",
	journal="BMC Bioinformatics",
	year="2019",
	month="Jun",
	day="27",
	volume="20",
	number="1",
	pages="358",
	abstract="In the last years more and more multi-omics data are becoming available, that is, data featuring measurements of several types of omics data for each patient. Using multi-omics data as covariate data in outcome prediction is both promising and challenging due to the complex structure of such data. Random forest is a prediction method known for its ability to render complex dependency patterns between the outcome and the covariates. Against this background we developed five candidate random forest variants tailored to multi-omics covariate data. These variants modify the split point selection of random forest to incorporate the block structure of multi-omics data and can be applied to any outcome type for which a random forest variant exists, such as categorical, continuous and survival outcomes. Using 20 publicly available multi-omics data sets with survival outcome we compared the prediction performances of the block forest variants with alternatives. We also considered the common special case of having clinical covariates and measurements of a single omics data type available.",
	issn="1471-2105",
	doi="10.1186/s12859-019-2942-y",
	url="https://doi.org/10.1186/s12859-019-2942-y"
}

% metaRbolomics {{{2
% TOREAD
@article{stanstrup2019_metaRbolomics,
	author="Stanstrup, Jan and Broeckling, Corey D. and Helmus, Rick and Hoffmann, Nils and Math{\'e}, Ewy and Naake, Thomas and Nicolotti, Luca and Peters, Kristian and Rainer, Johannes and Salek, Reza M. and Schulze, Tobias and Schymanski, Emma L. and Stravs, Michael A. and Th{\'e}venot, Etienne A. and Treutler, Hendrik and Weber, Ralf J. M. and Willighagen, Egon and Witting, Michael and Neumann, Steffen",
	title="The metaRbolomics Toolbox in Bioconductor and beyond.",
	journal="Metabolites",
	year="2019",
	month="Sep",
	day="23",
	volume="9",
	number="10",
	keywords="CRAN; NMR spectroscopy; R; bioconductor; compound identification; data integration; feature selection; lipidomics; mass Spectrometry; metabolite networks; metabolomics; signal processing; statistical data analysis",
	abstract="Metabolomics aims to measure and characterise the complex composition of metabolites  in a biological system. Metabolomics studies involve sophisticated analytical  techniques such as mass spectrometry and nuclear magnetic resonance spectroscopy,  and generate large amounts of high-dimensional and complex experimental data. Open  source processing and analysis tools are of major interest in light of innovative,  open and reproducible science. The scientific community has developed a wide range  of open source software, providing freely available advanced processing and analysis  approaches. The programming and statistics environment R has emerged as one of the  most popular environments to process and analyse Metabolomics datasets. A major  benefit of such an environment is the possibility of connecting different tools into  more complex workflows. Combining reusable data processing R scripts with the  experimental data thus allows for open, reproducible research. This review provides  an extensive overview of existing packages in R for different steps in a typical  computational metabolomics workflow, including data processing, biostatistics,  metabolite annotation and identification, and biochemical network and pathway  analysis. Multifunctional workflows, possible user interfaces and integration into  workflow management systems are also reviewed. In total, this review summarises more  than two hundred metabolomics specific packages primarily available on CRAN,  Bioconductor and GitHub.",
	doi="10.3390/metabo9100200",
	url="https://doi.org/10.3390/metabo9100200",
	url="http://www.ncbi.nlm.nih.gov/pubmed/31548506",
	url="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6835268",
	language="eng"
}

% TOREAD
@article{pleil2019,
	doi = {10.1088/1752-7163/ab2fa2},
	url = {https://doi.org/10.1088/1752-7163/ab2fa2},
	year = 2019,
	month = {aug},
	publisher = {{IOP} Publishing},
	volume = {13},
	number = {4},
	pages = {040201},
	author = {Joachim D Pleil and Antony Williams},
	title = {Centralized resource for chemicals from the human volatilome in an interactive open-sourced database},
	journal = {Journal of Breath Research},
	abstract = {}
}

@article{smith2020,
	author = {Smith, JM and Lathara, M and Wright, H and Hill, B and Ganapati, N and Srinivasa, G and others},
	year = {2020},
	title = {Advancing clinical cohort selection with genomics analysis on a distributed platform.},
	journal = {PLoS ONE},
	number = {15},
	volume = {4},
	pages = {e0231826},
	doi = {https://doi.org/10.1371/journal.pone.0231826}
}

@incollection{witting2018_bio_and_chemoinformatics_for_metabolomics,
	author = {Witting M.},
	year = {2018},
	title = {Bio- and Chemoinformatics Approaches for Metabolomics Data Analysis.},
	booktitle = {Metabolic Profiling: Methods and Protocols},
	editor = {Theodoridis G., Gika H., Wilson I.},
	series = {Methods in Molecular Biology},
	volume = {1738},
	chapter = {4},
	publisher = {Humana Press, New York, NY},
	doi = {https://doi.org/10.1007/978-1-4939-7643-0_4}
}
